
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "tutorials/tensordict_shapes.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_tutorials_tensordict_shapes.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_tutorials_tensordict_shapes.py:


Manipulating the shape of a TensorDict
======================================
**Author**: `Tom Begley <https://github.com/tcbegley>`_

In this tutorial you will learn how to manipulate the shape of a :class:`~.TensorDict`
and its contents.

.. GENERATED FROM PYTHON SOURCE LINES 12-17

When we create a :class:`~.TensorDict` we specify a ``batch_size``, which must agree
with the leading dimensions of all entries in the :class:`~.TensorDict`. Since we have
a guarantee that all entries share those dimensions in common, :class:`~.TensorDict`
is able to expose a number of methods with which we can manipulate the shape of the
:class:`~.TensorDict` and its contents.

.. GENERATED FROM PYTHON SOURCE LINES 17-21

.. code-block:: Python


    import torch
    from tensordict.tensordict import TensorDict








.. GENERATED FROM PYTHON SOURCE LINES 27-33

Indexing a ``TensorDict``
-------------------------

Since the batch dimensions are guaranteed to exist on all entries, we can index them
as we please, and each entry of the :class:`~.TensorDict` will be indexed in the same
way.

.. GENERATED FROM PYTHON SOURCE LINES 33-42

.. code-block:: Python


    a = torch.rand(3, 4)
    b = torch.rand(3, 4, 5)
    tensordict = TensorDict({"a": a, "b": b}, batch_size=[3, 4])

    indexed_tensordict = tensordict[:2, 1]
    assert indexed_tensordict["a"].shape == torch.Size([2])
    assert indexed_tensordict["b"].shape == torch.Size([2, 5])








.. GENERATED FROM PYTHON SOURCE LINES 43-50

Reshaping a ``TensorDict``
--------------------------

:meth:`TensorDict.reshape <tensordict.TensorDict.reshape>` works just like
:meth:`torch.Tensor.reshape`. It applies to all of the contents of the
:class:`~.TensorDict` along the batch dimensions - note the shape of ``b`` in the
example below. It also updates the ``batch_size`` attribute.

.. GENERATED FROM PYTHON SOURCE LINES 50-57

.. code-block:: Python



    reshaped_tensordict = tensordict.reshape(-1)
    assert reshaped_tensordict.batch_size == torch.Size([12])
    assert reshaped_tensordict["a"].shape == torch.Size([12])
    assert reshaped_tensordict["b"].shape == torch.Size([12, 5])








.. GENERATED FROM PYTHON SOURCE LINES 58-66

Splitting a ``TensorDict``
--------------------------

:meth:`TensorDict.split <tensordict.TensorDict.split>` is similar to
:meth:`torch.Tensor.split`. It splits the :class:`~.TensorDict` into chunks. Each
chunk is a :class:`~.TensorDict` with the same structure as the original one, but
whose entries are views of the corresponding entries in the original
:class:`~.TensorDict`.

.. GENERATED FROM PYTHON SOURCE LINES 66-72

.. code-block:: Python


    chunks = tensordict.split([3, 1], dim=1)
    assert chunks[0].batch_size == torch.Size([3, 3])
    assert chunks[1].batch_size == torch.Size([3, 1])
    torch.testing.assert_allclose(chunks[0]["a"], tensordict["a"][:, :-1])








.. GENERATED FROM PYTHON SOURCE LINES 73-107

.. note::

   Whenever a function or method accepts a ``dim`` argument, negative dimensions are
   interpreted relative to the ``batch_size`` of the :class:`~.TensorDict` that the
   function or method is called on. In particular, if there are nested
   :class:`~.TensorDict` values with different batch sizes, the negative dimension is
   always interpreted relative to the batch dimensions of the root.

   .. code-block::

      tensordict = TensorDict(
          {
              "a": torch.rand(3, 4),
              "nested": TensorDict({"b": torch.rand(3, 4, 5)}, [3, 4, 5])
          },
          [3, 4],
      )
      # dim = -2 will be interpreted as the first dimension throughout, as the root
      # TensorDict has 2 batch dimensions, even though the nested TensorDict has 3
      chunks = tensordict.split([2, 1], dim=-2)
      assert chunks[0].batch_size == torch.Size([2, 4])
      assert chunks[0]["nested"].batch_size == torch.Size([2, 4, 5])

   As you can see from this example, the
   :meth:`TensorDict.split <tensordict.TensorDict.split>` method behaves exactly as
   though we had replaced ``dim=-2`` with ``dim=tensordict.batch_dims - 2`` before
   calling.

Unbind
------
:meth:`TensorDict.unbind <tensordict.TensorDict.unbind>` is similar to
:meth:`torch.Tensor.unbind`, and conceptually similar to
:meth:`TensorDict.split <tensordict.TensorDict.split>`. It removes the specified
dimension and returns a ``tuple`` of all slices along that dimension.

.. GENERATED FROM PYTHON SOURCE LINES 107-113

.. code-block:: Python


    slices = tensordict.unbind(dim=1)
    assert len(slices) == 4
    assert all(s.batch_size == torch.Size([3]) for s in slices)
    torch.testing.assert_allclose(slices[0]["a"], tensordict["a"][:, 0])








.. GENERATED FROM PYTHON SOURCE LINES 114-125

Stacking and concatenating
--------------------------

:class:`~.TensorDict` can be used in conjunction with ``torch.cat`` and ``torch.stack``.

Stacking ``TensorDict``
^^^^^^^^^^^^^^^^^^^^^^^
By default, stacking is done in a lazy fashion, returning a
:class:`LazyStackedTensorDict` object. In this case values are only stacked on-demand
when they are accessed. This in cases where you have a large :class:`~.TensorDict` with
many entries, and you don't need to stack all of them.

.. GENERATED FROM PYTHON SOURCE LINES 125-131

.. code-block:: Python


    cloned_tensordict = tensordict.clone()
    # no stacking happens on the next line
    stacked_tensordict = torch.stack([tensordict, cloned_tensordict], dim=0)
    print(stacked_tensordict)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    LazyStackedTensorDict(
        fields={
            a: Tensor(shape=torch.Size([2, 3, 4]), device=cpu, dtype=torch.float32, is_shared=False),
            b: Tensor(shape=torch.Size([2, 3, 4, 5]), device=cpu, dtype=torch.float32, is_shared=False)},
        exclusive_fields={
        },
        batch_size=torch.Size([2, 3, 4]),
        device=None,
        is_shared=False,
        stack_dim=0)




.. GENERATED FROM PYTHON SOURCE LINES 132-134

If we index a :class:`~.LazyStackedTensorDict` along the stacking dimension we recover
the original :class:`~.TensorDict`.

.. GENERATED FROM PYTHON SOURCE LINES 134-138

.. code-block:: Python


    assert stacked_tensordict[0] is tensordict
    assert stacked_tensordict[1] is cloned_tensordict








.. GENERATED FROM PYTHON SOURCE LINES 139-142

Accessing a key in the :class:`~.LazyStackedTensorDict` results in those values being
stacked. If the key corresponds to a nested :class:`~.TensorDict` then we will recover
another :class:`~.LazyStackedTensorDict`.

.. GENERATED FROM PYTHON SOURCE LINES 142-145

.. code-block:: Python


    assert stacked_tensordict["a"].shape == torch.Size([2, 3, 4])








.. GENERATED FROM PYTHON SOURCE LINES 146-170

.. note::

   Since values are stacked on-demand, accessing an item multiple times will mean it
   gets stacked multiple times, which is inefficient. If you need to access a value
   in the stacked :class:`~.TensorDict` more than once, you may want to consider
   converting the :class:`LazyStackedTensorDict` to a contiguous
   :class:`~.TensorDict`, which can be done with the
   :meth:`LazyStackedTensorDict.to_tensordict <tensordict.LazyStackedTensorDict.to_tensordict>`
   or :meth:`LazyStackedTensorDict.contiguous <tensordict.LazyStackedTensorDict.contiguous>`
   methods.

   .. code-block::
      assert isinstance(stacked_tensordict.contiguous(), TensorDict)
      assert isinstance(stacked_tensordict.contiguous(), TensorDict)

   After calling either of these methods, we will have a regular :class:`TensorDict`
   containing the stacked values, and no additional computation is performed when
   values are accessed.

Concatenating ``TensorDict``
^^^^^^^^^^^^^^^^^^^^^^^^^^^^
Concatenation is not done lazily, instead calling :func:`torch.cat` on a list of
:class:`~.TensorDict` instances simply returns a :class:`~.TensorDict` whose entries
are the concatenated entries of the elements of the list.

.. GENERATED FROM PYTHON SOURCE LINES 170-176

.. code-block:: Python


    concatenated_tensordict = torch.cat([tensordict, cloned_tensordict], dim=0)
    assert isinstance(concatenated_tensordict, TensorDict)
    assert concatenated_tensordict.batch_size == torch.Size([6, 4])
    assert concatenated_tensordict["b"].shape == torch.Size([6, 4, 5])








.. GENERATED FROM PYTHON SOURCE LINES 177-181

Expanding ``TensorDict``
------------------------
We can expand all of the entries of a :class:`~.TensorDict` using
:meth:`TensorDict.expand <tensordict.TensorDict.expand>`.

.. GENERATED FROM PYTHON SOURCE LINES 181-186

.. code-block:: Python


    exp_tensordict = tensordict.expand(2, *tensordict.batch_size)
    assert exp_tensordict.batch_size == torch.Size([2, 3, 4])
    torch.testing.assert_allclose(exp_tensordict["a"][0], exp_tensordict["a"][1])








.. GENERATED FROM PYTHON SOURCE LINES 187-197

Squeezing and Unsqueezing ``TensorDict``
----------------------------------------
We can squeeze or unsqueeze the contents of a :class:`~.TensorDict` with the
:meth:`TensorDict.squeeze <tensordict.TensorDict.squeeze>` and
:meth:`TensorDict.unsqueeze <tensordict.TensorDict.unsqueeze>` methods. These
operations are both lazy, and return
:class:`_SqueezedTensorDict <tensordict.tensordict._SqueezedTensorDict>` and
:class:`_UnsqueezedTensorDict <tensordict.tensordict._UnsqueezedTensorDict>`
respectively. Like in the case of stacking and :class:`~.LazyStackedTensorDict`, the
squeezing or unsqueezing is only performed when we try to access an entry.

.. GENERATED FROM PYTHON SOURCE LINES 197-208

.. code-block:: Python



    tensordict = TensorDict({"a": torch.rand(3, 1, 4)}, [3, 1, 4])
    squeezed_tensordict = tensordict.squeeze()
    assert squeezed_tensordict["a"].shape == torch.Size([3, 4])
    print(squeezed_tensordict, end="\n\n")

    unsqueezed_tensordict = tensordict.unsqueeze(-1)
    assert unsqueezed_tensordict["a"].shape == torch.Size([3, 1, 4, 1])
    print(unsqueezed_tensordict)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    _SqueezedTensorDict(
            source=TensorDict(
                fields={
                    a: Tensor(shape=torch.Size([3, 1, 4]), device=cpu, dtype=torch.float32, is_shared=False)},
                batch_size=torch.Size([3, 1, 4]),
                device=None,
                is_shared=False), 
            op=squeeze(dim=1))

    _UnsqueezedTensorDict(
            source=TensorDict(
                fields={
                    a: Tensor(shape=torch.Size([3, 1, 4]), device=cpu, dtype=torch.float32, is_shared=False)},
                batch_size=torch.Size([3, 1, 4]),
                device=None,
                is_shared=False), 
            op=unsqueeze(dim=3))




.. GENERATED FROM PYTHON SOURCE LINES 209-227

.. note::

   If you are likely to repeated access the same entry in the squeezed or unsqueezed
   tensordict, then it may be beneficial to first convert to a regular
   :class:`~.TensorDict` using :meth:`.to_tensordict()`

   .. code-block::

      tensordict = TensorDict({"a": torch.rand(3, 1, 4)}, [3, 1, 4])
      squeezed_tensordict = tensordict.squeeze().to_tensordict()
      assert isinstance(squeezed_tensordict, TensorDict)
      assert squeezed_tensordict.batch_size == torch.Size([3, 1, 4])

   In this case, ``squeezed_tensordict`` is a regular :class:`TensorDict` containing
   the squeezed tensors.

Bear in mind that as ever, these methods apply only to the batch dimensions. Any non
batch dimensions of the entries will be unaffected

.. GENERATED FROM PYTHON SOURCE LINES 227-234

.. code-block:: Python


    tensordict = TensorDict({"a": torch.rand(3, 1, 1, 4)}, [3, 1])
    squeezed_tensordict = tensordict.squeeze()
    # only one of the singleton dimensions is dropped as the other
    # is not a batch dimension
    assert squeezed_tensordict["a"].shape == torch.Size([3, 1, 4])








.. GENERATED FROM PYTHON SOURCE LINES 235-239

Viewing a TensorDict
--------------------
:class:`~.TensorDict` also supports ``view``. This creates a ``_ViewedTensorDict``
which lazily creates views on its contents when they are accessed.

.. GENERATED FROM PYTHON SOURCE LINES 239-248

.. code-block:: Python


    tensordict = TensorDict({"a": torch.arange(12)}, [12])
    # no views are created at this step
    viewed_tensordict = tensordict.view((2, 3, 2))

    # the view of "a" is created on-demand when we access it
    assert viewed_tensordict["a"].shape == torch.Size([2, 3, 2])









.. GENERATED FROM PYTHON SOURCE LINES 249-258

Permuting batch dimensions
--------------------------
The :meth:`TensorDict.permute <tensordict.TensorDict.permute>` method can be used to
permute the batch dimensions much like :func:`torch.permute`. Non batch dimensions are
left untouched.

This operation is lazy, so batch dimensions are only permuted when we try to access
the entries. As ever, if you are likely to need to access a particular entry multiple
times, consider converting to a :class:`~.TensorDict`.

.. GENERATED FROM PYTHON SOURCE LINES 258-266

.. code-block:: Python


    tensordict = TensorDict({"a": torch.rand(3, 4), "b": torch.rand(3, 4, 5)}, [3, 4])
    # swap the batch dimensions
    permuted_tensordict = tensordict.permute([1, 0])

    assert permuted_tensordict["a"].shape == torch.Size([4, 3])
    assert permuted_tensordict["b"].shape == torch.Size([4, 3, 5])








.. GENERATED FROM PYTHON SOURCE LINES 267-272

Gathering values in ``TensorDict``
----------------------------------
The :meth:`TensorDict.gather <tensordict.TensorDict.gather>` method can be used to
index along the batch dimensions and gather the results into a single dimension much
like :func:`torch.gather`.

.. GENERATED FROM PYTHON SOURCE LINES 272-278

.. code-block:: Python


    index = torch.randint(4, (3, 4))
    gathered_tensordict = tensordict.gather(dim=1, index=index)
    print("index:\n", index, end="\n\n")
    print("tensordict['a']:\n", tensordict["a"], end="\n\n")
    print("gathered_tensordict['a']:\n", gathered_tensordict["a"], end="\n\n")




.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    index:
     tensor([[0, 1, 0, 2],
            [1, 3, 3, 2],
            [2, 2, 2, 1]])

    tensordict['a']:
     tensor([[0.1789, 0.5129, 0.8682, 0.8557],
            [0.1385, 0.8781, 0.4334, 0.8685],
            [0.4700, 0.6371, 0.1841, 0.7191]])

    gathered_tensordict['a']:
     tensor([[0.1789, 0.5129, 0.1789, 0.8682],
            [0.8781, 0.8685, 0.8685, 0.4334],
            [0.1841, 0.1841, 0.1841, 0.6371]])






.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (0 minutes 0.010 seconds)


.. _sphx_glr_download_tutorials_tensordict_shapes.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: tensordict_shapes.ipynb <tensordict_shapes.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: tensordict_shapes.py <tensordict_shapes.py>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
